services:
  zookeeper:
    image: bitnami/zookeeper:latest
    platform: linux/arm64
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    volumes:
      - zookeeper_data:/bitnami/zookeeper

  kafka:
    image: bitnami/kafka:3.4.0
    platform: linux/arm64
    container_name: kafka
    ports:
      - "9092:9092" # Host (Mac) access
      - "29092:29092" # Docker-internal access for Kafka UI
    environment:
      - KAFKA_ENABLE_KRAFT= "no"
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CFG_LISTENERS=PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092,PLAINTEXT_HOST://kafka:29092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - ALLOW_PLAINTEXT_LISTENER=yes
      - BITNAMI_DEBUG=true
    depends_on:
      - zookeeper
    volumes:
      - kafka_data:/bitnami/kafka

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    platform: linux/arm64
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:29092
    depends_on:
      - kafka

  kafka-create-topic:
    image: bitnami/kafka:3.4.0
    platform: linux/arm64
    depends_on:
      - kafka
    entrypoint: ["/bin/bash", "-c"]
    command:
      - |
        /opt/bitnami/kafka/bin/kafka-topics.sh \
          --create \
          --topic transcode \
          --partitions 1 \
          --replication-factor 1 \
          --if-not-exists \
          --bootstrap-server kafka:29092

  postgres:
    image: postgres:15-alpine
    platform: linux/arm64
    container_name: postgres
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=videostore
      - POSTGRES_PASSWORD=videopass
      - POSTGRES_DB=videodb
    volumes:
      - postgres_data:/var/lib/postgresql/data

  client:
    build:
      context: ./client
      dockerfile: Dockerfile
    image: client:latest
    container_name: client
    ports:
      - "3000:3000"
    environment:
      - WATCH_SERVICE=http://watch_service:8003
      - NEXTAUTH_URL=http://localhost:3000
      - GOOGLE_CLIENT_ID=
      - GOOGLE_CLIENT_SECRET=
      - NEXTAUTH_SECRET=
      - NEXT_PUBLIC_UPLOAD_SERVICE=
      # Add other client env vars as needed
    depends_on:
      - watch

  watch:
    build:
      context: ./watch_service
      dockerfile: Dockerfile
    image: watch_service:latest
    container_name: watch_service
    ports:
      - "8003:8003"
    environment:
      - AWS_ACCESS_KEY=
      - AWS_SECRET_ACCESS_KEY=
      - S3_BUCKET_NAME=
      - AWS_REGION=
      - PG_DATABASE_URL=
    depends_on:
      - postgres

  upload:
    build:
      context: ./upload_service
      dockerfile: Dockerfile
    image: upload_service:latest
    container_name: upload_service
    ports:
      - "8000:8000"
    environment:
      - AWS_ACCESS_KEY=
      - AWS_SECRET_ACCESS_KEY=
      - S3_BUCKET_NAME=
      - AWS_REGION=
      - PG_DATABASE_URL=
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
    depends_on:
      - postgres
      - kafka

  transcode:
    build:
      context: ./transcoder_service
      dockerfile: Dockerfile
    image: transcode_service:latest
    container_name: transcode_service
    environment:
      - AWS_ACCESS_KEY=
      - AWS_SECRET_ACCESS_KEY=
      - S3_BUCKET_NAME=
      - AWS_REGION=
      - PG_DATABASE_URL=
      - KAFKA_BOOTSTRAP_SERVERS=
      - KAFKA_CONSUMER_GROUP_ID=
    volumes:
      - ./.watch_data:/app/hls
    depends_on:
      - kafka
      - upload

volumes:
  zookeeper_data:
  kafka_data:
  postgres_data:
